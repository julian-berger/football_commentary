{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (1.2.0)\n",
      "Requirement already satisfied: fasterrisk in ./.venv/lib/python3.9/site-packages (0.1.10)\n",
      "Requirement already satisfied: imblearn in ./.venv/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: xgboost in ./.venv/lib/python3.9/site-packages (2.1.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (3.2.1)\n",
      "Requirement already satisfied: interpret in ./.venv/lib/python3.9/site-packages (0.6.9)\n",
      "Collecting sdv\n",
      "  Downloading sdv-1.17.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: matplotlib==3.7.2 in ./.venv/lib/python3.9/site-packages (from fasterrisk) (3.7.2)\n",
      "Requirement already satisfied: pillow==9.4.0 in ./.venv/lib/python3.9/site-packages (from fasterrisk) (9.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in ./.venv/lib/python3.9/site-packages (from fasterrisk) (2.32.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2->fasterrisk) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2->fasterrisk) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2->fasterrisk) (4.55.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2->fasterrisk) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2->fasterrisk) (24.2)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2->fasterrisk) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2->fasterrisk) (6.5.2)\n",
      "Requirement already satisfied: imbalanced-learn in ./.venv/lib/python3.9/site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: interpret-core==0.6.9 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.6.9)\n",
      "Requirement already satisfied: plotly>=3.8.1 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (5.24.1)\n",
      "Requirement already satisfied: dash>=1.0.0 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (2.18.2)\n",
      "Requirement already satisfied: dash-core-components>=1.0.0 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (2.0.0)\n",
      "Requirement already satisfied: dash-html-components>=1.0.0 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (2.0.0)\n",
      "Requirement already satisfied: dash-table>=4.1.0 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (5.0.0)\n",
      "Requirement already satisfied: dash-cytoscape>=0.1.1 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (1.0.2)\n",
      "Requirement already satisfied: gevent>=1.3.6 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (24.11.1)\n",
      "Requirement already satisfied: SALib>=1.3.3 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (1.4.8)\n",
      "Requirement already satisfied: shap>=0.28.5 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.46.0)\n",
      "Requirement already satisfied: dill>=0.2.5 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.3.9)\n",
      "Requirement already satisfied: aplr>=10.6.1 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (10.8.0)\n",
      "Requirement already satisfied: ipykernel>=4.10.0 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (6.29.5)\n",
      "Requirement already satisfied: ipython>=5.5.0 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (8.18.1)\n",
      "Requirement already satisfied: psutil>=5.6.2 in ./.venv/lib/python3.9/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (6.1.1)\n",
      "Collecting boto3<2.0.0,>=1.28 (from sdv)\n",
      "  Downloading boto3-1.36.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<2.0.0,>=1.31 (from sdv)\n",
      "  Downloading botocore-1.36.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cloudpickle>=2.1.0 in ./.venv/lib/python3.9/site-packages (from sdv) (3.1.1)\n",
      "Collecting graphviz>=0.13.2 (from sdv)\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tqdm>=4.29 in ./.venv/lib/python3.9/site-packages (from sdv) (4.67.1)\n",
      "Collecting copulas>=0.12.0 (from sdv)\n",
      "  Downloading copulas-0.12.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting ctgan>=0.10.2 (from sdv)\n",
      "  Downloading ctgan-0.10.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting deepecho>=0.6.1 (from sdv)\n",
      "  Downloading deepecho-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting rdt>=1.13.2 (from sdv)\n",
      "  Downloading rdt-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sdmetrics>=0.17.0 (from sdv)\n",
      "  Downloading sdmetrics-0.18.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: platformdirs>=4.0 in ./.venv/lib/python3.9/site-packages (from sdv) (4.3.6)\n",
      "Collecting pyyaml>=6.0.1 (from sdv)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.28->sdv)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2.0.0,>=1.28->sdv)\n",
      "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore<2.0.0,>=1.31->sdv)\n",
      "  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting torch>=1.9.0 (from ctgan>=0.10.2->sdv)\n",
      "  Using cached torch-2.5.1-cp39-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n",
      "Collecting Faker>=17 (from rdt>=1.13.2->sdv)\n",
      "  Downloading Faker-35.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (2024.12.14)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in ./.venv/lib/python3.9/site-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in ./.venv/lib/python3.9/site-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (3.0.6)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.9/site-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (8.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.9/site-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (4.12.2)\n",
      "Requirement already satisfied: retrying in ./.venv/lib/python3.9/site-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.9/site-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (1.6.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (from dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (58.0.4)\n",
      "Requirement already satisfied: greenlet>=3.1.1 in ./.venv/lib/python3.9/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (3.1.1)\n",
      "Requirement already satisfied: zope.event in ./.venv/lib/python3.9/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (5.0)\n",
      "Requirement already satisfied: zope.interface in ./.venv/lib/python3.9/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (7.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.2->fasterrisk) (3.21.0)\n",
      "Requirement already satisfied: appnope in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (1.8.12)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.1.7)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (5.14.3)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.9/site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.9/site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.9/site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.9/site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (2.19.1)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.9/site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.9/site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.9/site-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (4.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.venv/lib/python3.9/site-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (9.0.0)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.9/site-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.70.17)\n",
      "Requirement already satisfied: slicer==0.0.8 in ./.venv/lib/python3.9/site-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.0.8)\n",
      "Requirement already satisfied: numba in ./.venv/lib/python3.9/site-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.60.0)\n",
      "Collecting filelock (from torch>=1.9.0->ctgan>=0.10.2->sdv)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch>=1.9.0->ctgan>=0.10.2->sdv) (3.1.5)\n",
      "Collecting fsspec (from torch>=1.9.0->ctgan>=0.10.2->sdv)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.9.0->ctgan>=0.10.2->sdv)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.9.0->ctgan>=0.10.2->sdv)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./.venv/lib/python3.9/site-packages (from Flask<3.1,>=1.0.4->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.venv/lib/python3.9/site-packages (from Flask<3.1,>=1.0.4->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./.venv/lib/python3.9/site-packages (from Flask<3.1,>=1.0.4->dash>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (1.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch>=1.9.0->ctgan>=0.10.2->sdv) (3.0.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.2.13)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.venv/lib/python3.9/site-packages (from numba->shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.43.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret) (0.2.3)\n",
      "Downloading sdv-1.17.4-py3-none-any.whl (154 kB)\n",
      "Downloading boto3-1.36.5-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.36.5-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading copulas-0.12.1-py3-none-any.whl (52 kB)\n",
      "Downloading ctgan-0.10.2-py3-none-any.whl (23 kB)\n",
      "Downloading deepecho-0.6.1-py3-none-any.whl (27 kB)\n",
      "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Downloading rdt-1.13.2-py3-none-any.whl (66 kB)\n",
      "Downloading sdmetrics-0.18.0-py3-none-any.whl (179 kB)\n",
      "Downloading Faker-35.0.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
      "Using cached torch-2.5.1-cp39-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, urllib3, sympy, pyyaml, jmespath, graphviz, fsspec, filelock, torch, Faker, botocore, s3transfer, rdt, deepecho, copulas, sdmetrics, ctgan, boto3, sdv\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "Successfully installed Faker-35.0.0 boto3-1.36.5 botocore-1.36.5 copulas-0.12.1 ctgan-0.10.2 deepecho-0.6.1 filelock-3.17.0 fsspec-2024.12.0 graphviz-0.20.3 jmespath-1.0.1 mpmath-1.3.0 pyyaml-6.0.2 rdt-1.13.2 s3transfer-0.11.2 sdmetrics-0.18.0 sdv-1.17.4 sympy-1.13.1 torch-2.5.1 urllib3-1.26.20\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas numpy scikit-learn fasterrisk imblearn xgboost networkx interpret sdv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested on python 3.9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berger/Documents/soccer/commentary_supplement/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "import fasterrisk.fasterrisk\n",
    "from fasterrisk.fasterrisk import RiskScoreOptimizer, RiskScoreClassifier\n",
    "from fasterrisk.binarization_util import convert_continuous_df_to_binary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "#import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import interpret\n",
    "from interpret import show\n",
    "from interpret.glassbox import ExplainableBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all data and iterate over test set player IDs\n",
    "\n",
    "The goal is to test fasterrisk and EBMs on the same test-splits like the Hecksteden et al. (2022) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv(\"/Users/berger/Documents/soccer/positron_project/data_ml_praevent.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasterrisk with sparsity constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting continuous features to binary features in the dataframe......\n",
      "We select thresholds for each continuous feature by sampling (without replacement) <= max_num_thresholds_per_feature values from all unique values in that feature column.\n",
      "Finish converting continuous features to binary features......\n",
      "Converting continuous features to binary features in the dataframe......\n",
      "We select thresholds for each continuous feature by sampling (without replacement) <= max_num_thresholds_per_feature values from all unique values in that feature column.\n",
      "Finish converting continuous features to binary features......\n",
      "Converting continuous features to binary features in the dataframe......\n",
      "We select thresholds for each continuous feature by sampling (without replacement) <= max_num_thresholds_per_feature values from all unique values in that feature column.\n",
      "Finish converting continuous features to binary features......\n",
      "Converting continuous features to binary features in the dataframe......\n",
      "We select thresholds for each continuous feature by sampling (without replacement) <= max_num_thresholds_per_feature values from all unique values in that feature column.\n",
      "Finish converting continuous features to binary features......\n"
     ]
    }
   ],
   "source": [
    "auc_frisk=[]\n",
    "\n",
    "for i in range(1, 5):\n",
    "    filename = f\"data_test_{i}_old.csv\"\n",
    "\n",
    "    file = pd.read_csv(filename)\n",
    "    ids=file['ID']\n",
    "\n",
    "    ID=all_data['ID']\n",
    "\n",
    "    y=all_data['Crit']\n",
    "\n",
    "    binarized, featureIndex_to_groupIndex=convert_continuous_df_to_binary_df(all_data.drop(columns=[\"Crit\",'ID']),max_num_thresholds_per_feature=25,get_featureIndex_to_groupIndex=True)\n",
    "\n",
    "    binarized['ID']=ID\n",
    "    binarized['y']=y\n",
    "\n",
    "    #ensure player IDs from the test data are not in the train data\n",
    "    train=binarized[~binarized['ID'].isin(ids)]\n",
    "    test=binarized[binarized['ID'].isin(ids)]\n",
    "\n",
    "    train=train.drop(columns=[\"ID\"])\n",
    "    test=test.drop(columns=[\"ID\"])\n",
    "\n",
    "    X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "    X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
    "\n",
    "\n",
    "    y_train_frisk=np.asarray(y_train)\n",
    "    y_train_frisk[y_train_frisk == 1] = 1\n",
    "    y_train_frisk[y_train_frisk == 0] = -1\n",
    "    y_train_frisk\n",
    "\n",
    "    y_test_frisk=np.asarray(y_test)\n",
    "    y_test_frisk[y_test_frisk == 1] = 1\n",
    "    y_test_frisk[y_test_frisk == 0] = -1\n",
    "    y_test_frisk\n",
    "\n",
    "\n",
    "    sparsity = 8\n",
    "    parent_size = 10\n",
    "    ub=10\n",
    "    lb=ub*-1\n",
    "    sparsity_constraint=8\n",
    "\n",
    "    RiskScoreOptimizer_m = RiskScoreOptimizer(X = np.array(X_train), y = y_train_frisk, \n",
    "                                                    k = sparsity,\n",
    "                                                    parent_size=parent_size, \n",
    "                                                    select_top_m=1,\n",
    "                                                    ub=ub,\n",
    "                                                    lb=lb,\n",
    "                                                    maxAttempts=10,\n",
    "                                                    featureIndex_to_groupIndex = featureIndex_to_groupIndex,\n",
    "                                                    group_sparsity=sparsity_constraint)\n",
    "    RiskScoreOptimizer_m.optimize()\n",
    "    multipliers, sparseDiversePool_beta0_integer, sparseDiversePool_betas_integer = RiskScoreOptimizer_m.get_models()\n",
    "    model_index = 0 # first model\n",
    "    multiplier = multipliers[model_index]\n",
    "    intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "    coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "    #RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients)\n",
    "\n",
    "    feature_names=list(X_train.columns)\n",
    "    RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients, X_train = X_train)\n",
    "    #RiskScoreClassifier_m.reset_featureNames(feature_names)\n",
    "    #RiskScoreClassifier_m.print_model_card()\n",
    "        \n",
    "    y_test_pred=RiskScoreClassifier_m.predict_prob(np.asarray(X_test))\n",
    "\n",
    "    test_acc, test_auc = RiskScoreClassifier_m.get_acc_and_auc(np.asarray(X_test), y_test_frisk)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test,y_score=y_test_pred)    \n",
    "    df = pd.DataFrame(zip(fpr,tpr,thresholds), columns = ['false_positive_rate', 'true_positive_rate', 'thresholds'])   \n",
    "    df.to_csv(\"roc_curve_frisk_\"+str(i)+\".csv\")\n",
    "\n",
    "    auc_frisk.append(test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.6168531006743642),\n",
       " np.float64(0.6176590909090909),\n",
       " np.float64(0.6400319656874647),\n",
       " np.float64(0.6892719947531154)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_frisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6409540380060088\n",
      "0.02940656772766909\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_frisk))\n",
    "print(np.std(auc_frisk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize fasterrisk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting continuous features to binary features in the dataframe......\n",
      "We select thresholds for each continuous feature by sampling (without replacement) <= max_num_thresholds_per_feature values from all unique values in that feature column.\n",
      "Finish converting continuous features to binary features......\n",
      "The Risk Score is:\n",
      "1.    VV_resid_age<=-96.4526726784976     -1 point(s) |   ...\n",
      "2.                          IAT<=13.3     -1 point(s) | + ...\n",
      "3.                    Sprint_30<=4.59     -2 point(s) | + ...\n",
      "4.                 SIMS_score<=19.875     -1 point(s) | + ...\n",
      "5.                 SIMS_score<=20.625      2 point(s) | + ...\n",
      "6.                       SIMS_pain<=0     -1 point(s) | + ...\n",
      "7.                       Matchday<=ja      1 point(s) | + ...\n",
      "8.                  Srpe_team_avg<=80     -2 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -8.0  |  -7.0  |  -6.0  |  -5.0  |  -4.0  |  -3.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |\n",
      "SCORE |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |\n",
      "RISK  |   0.3% |   0.7% |   1.6% |   3.6% |   7.9% |  16.2% |\n"
     ]
    }
   ],
   "source": [
    "filename = f\"data_test_{4}_old.csv\"\n",
    "\n",
    "file = pd.read_csv(filename)\n",
    "ids=file['ID']\n",
    "\n",
    "#train=all_data[~all_data['ID'].isin(ids)]\n",
    "#test=all_data[all_data['ID'].isin(ids)]\n",
    "\n",
    "ID=all_data['ID']\n",
    "\n",
    "y=all_data['Crit']\n",
    "\n",
    "binarized, featureIndex_to_groupIndex=convert_continuous_df_to_binary_df(all_data.drop(columns=[\"Crit\",'ID']),max_num_thresholds_per_feature=25,get_featureIndex_to_groupIndex=True)\n",
    "\n",
    "binarized['ID']=ID\n",
    "binarized['y']=y\n",
    "\n",
    "train=binarized[~binarized['ID'].isin(ids)]\n",
    "test=binarized[binarized['ID'].isin(ids)]\n",
    "\n",
    "train=train.drop(columns=[\"ID\"])\n",
    "test=test.drop(columns=[\"ID\"])\n",
    "\n",
    "X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
    "\n",
    "\n",
    "y_train_frisk=np.asarray(y_train)\n",
    "y_train_frisk[y_train_frisk == 1] = 1\n",
    "y_train_frisk[y_train_frisk == 0] = -1\n",
    "y_train_frisk\n",
    "\n",
    "y_test_frisk=np.asarray(y_test)\n",
    "y_test_frisk[y_test_frisk == 1] = 1\n",
    "y_test_frisk[y_test_frisk == 0] = -1\n",
    "y_test_frisk\n",
    "\n",
    "sparsity = 8\n",
    "parent_size = 10\n",
    "ub=10\n",
    "lb=ub*-1\n",
    "sparsity_constraint=8\n",
    "\n",
    "RiskScoreOptimizer_m = RiskScoreOptimizer(X = np.asarray(X_train), y = y_train_frisk, \n",
    "                                                  k = sparsity,\n",
    "                                                  parent_size=parent_size, \n",
    "                                                  select_top_m=10,\n",
    "                                                  ub=ub,\n",
    "                                                  lb=lb,\n",
    "                                                  maxAttempts=10,\n",
    "                                                  group_sparsity=sparsity_constraint,\n",
    "                                                  featureIndex_to_groupIndex = featureIndex_to_groupIndex\n",
    "                                                  )\n",
    "RiskScoreOptimizer_m.optimize()\n",
    "multipliers, sparseDiversePool_beta0_integer, sparseDiversePool_betas_integer = RiskScoreOptimizer_m.get_models()\n",
    "model_index = 0 # first model\n",
    "multiplier = multipliers[model_index]\n",
    "intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "#RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients)\n",
    "\n",
    "feature_names=list(X_train.columns)\n",
    "RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients, X_train = X_train)\n",
    "RiskScoreClassifier_m.reset_featureNames(feature_names)\n",
    "RiskScoreClassifier_m.print_model_card()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -2 point(s) |   ...\n",
      "2.     VV_resid_age<=89.9301129761037      1 point(s) | + ...\n",
      "3.                          Fat<=20.1     -4 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      2 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -3 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      3 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -3 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -3 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |  -6.0  |  -5.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.2% |   0.4% |   0.7% |\n",
      "SCORE |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |   1.2% |   2.1% |   3.5% |   6.0% |  10.0% |  16.1% |  25.0% |  36.6% |  50.0% |  63.4% |  75.0% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -2 point(s) |   ...\n",
      "2.                           Fat<=9.3      2 point(s) | + ...\n",
      "3.                          IAT<=13.2     -4 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      4 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -6 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      5 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -5 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -5 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -22.0  |  -20.0  |  -18.0  |  -17.0  |  -16.0  |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |  -6.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.1% |   0.1% |   0.2% |\n",
      "SCORE |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |   7.0  |   9.0  |  11.0  |\n",
      "RISK  |   0.3% |   0.4% |   0.5% |   0.7% |   0.9% |   1.3% |   1.7% |   2.3% |   3.2% |   4.3% |   5.7% |   7.7% |  10.2% |  17.4% |  28.2% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=27.1645416669011     -1 point(s) |   ...\n",
      "2.                          Fat<=20.1     -4 point(s) | + ...\n",
      "3.                          IAT<=13.2     -2 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      2 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -3 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      3 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -3 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -3 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -16.0  |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |  -6.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.2% |   0.3% |   0.5% |\n",
      "SCORE |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |\n",
      "RISK  |   0.8% |   1.3% |   2.3% |   3.8% |   6.4% |  10.4% |  16.6% |  25.5% |  36.9% |  50.0% |  63.1% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=55.1942130596619     -1 point(s) |   ...\n",
      "2.                          Fat<=20.1     -4 point(s) | + ...\n",
      "3.                          IAT<=13.2     -2 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      2 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -3 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      3 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -3 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -3 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -16.0  |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |  -6.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.2% |   0.3% |   0.5% |\n",
      "SCORE |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |\n",
      "RISK  |   0.8% |   1.4% |   2.3% |   3.9% |   6.4% |  10.5% |  16.7% |  25.5% |  36.9% |  50.0% |  63.1% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -2 point(s) |   ...\n",
      "2.                          Fat<=20.1     -6 point(s) | + ...\n",
      "3.                          IAT<=13.2     -3 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      3 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -5 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      4 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -4 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -4 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -24.0  |  -22.0  |  -21.0  |  -20.0  |  -19.0  |  -18.0  |  -17.0  |  -16.0  |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.1% |   0.2% |   0.2% |   0.4% |   0.5% |\n",
      "SCORE |  -8.0  |  -7.0  |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   7.0  |\n",
      "RISK  |   0.8% |   1.1% |   1.6% |   2.3% |   3.3% |   4.7% |   6.7% |   9.5% |  13.3% |  18.2% |  24.5% |  32.1% |  40.7% |  50.0% |  67.9% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -2 point(s) |   ...\n",
      "2.     VV_resid_age<=89.9301129761037      1 point(s) | + ...\n",
      "3.                          IAT<=13.2     -2 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      2 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -3 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      3 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -3 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -3 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |  -6.0  |  -5.0  |  -4.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.2% |\n",
      "SCORE |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |   0.3% |   0.4% |   0.7% |   1.2% |   1.9% |   3.1% |   5.0% |   7.9% |  12.3% |  18.7% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -2 point(s) |   ...\n",
      "2.                          Fat<=18.6     -4 point(s) | + ...\n",
      "3.                          IAT<=13.2     -3 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      3 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -5 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      4 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -4 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -4 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -22.0  |  -20.0  |  -19.0  |  -18.0  |  -17.0  |  -16.0  |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.2% |   0.2% |   0.3% |\n",
      "SCORE |  -7.0  |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   7.0  |\n",
      "RISK  |   0.5% |   0.8% |   1.2% |   1.7% |   2.6% |   3.8% |   5.6% |   8.1% |  11.7% |  16.6% |  22.9% |  30.8% |  40.0% |  60.0% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -2 point(s) |   ...\n",
      "2.                           Fat<=9.3      1 point(s) | + ...\n",
      "3.                          Fat<=20.1     -6 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      3 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -5 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      4 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -4 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -4 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -21.0  |  -20.0  |  -19.0  |  -18.0  |  -17.0  |  -16.0  |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.2% |   0.2% |   0.4% |   0.5% |   0.8% |   1.2% |\n",
      "SCORE |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |   7.0  |   8.0  |\n",
      "RISK  |   1.8% |   2.6% |   3.8% |   5.6% |   8.2% |  11.8% |  16.7% |  23.0% |  30.9% |  40.1% |  50.0% |  59.9% |  69.1% |  77.0% |  83.3% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -2 point(s) |   ...\n",
      "2.     VV_resid_age<=95.9301129761037      1 point(s) | + ...\n",
      "3.                          IAT<=13.2     -2 point(s) | + ...\n",
      "4.                 SIMS_score<=20.625      2 point(s) | + ...\n",
      "5.                       SIMS_pain<=0     -3 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.457326892109501      3 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.123980424143556     -3 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -3 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |  -6.0  |  -5.0  |  -4.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.2% |\n",
      "SCORE |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |   0.3% |   0.4% |   0.7% |   1.2% |   1.9% |   3.1% |   4.9% |   7.8% |  12.2% |  18.6% |\n",
      "The Risk Score is:\n",
      "1.     VV_resid_age<=59.1942130596619     -3 point(s) |   ...\n",
      "2.                          IAT<=13.2     -5 point(s) | + ...\n",
      "3.                 SIMS_score<=20.625      4 point(s) | + ...\n",
      "4.                       SIMS_pain<=0     -7 point(s) | + ...\n",
      "5. Srpe_7d_robust<=-0.457326892109501      6 point(s) | + ...\n",
      "6.  Srpe_7d_robust<=0.123980424143556     -5 point(s) | + ...\n",
      "7.                       Matchday<=ja      2 point(s) | + ...\n",
      "8.                 Srpe_team_avg<=170     -6 point(s) | + ...\n",
      "                                                SCORE | =    \n",
      "SCORE |  -26.0  |  -24.0  |  -23.0  |  -22.0  |  -21.0  |  -20.0  |  -19.0  |  -18.0  |  -17.0  |  -16.0  |  -15.0  |  -14.0  |  -13.0  |  -12.0  |  -11.0  |  -10.0  |  -9.0  |  -8.0  |  -7.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.1% |   0.1% |   0.1% |   0.1% |   0.2% |   0.2% |   0.2% |\n",
      "SCORE |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |   7.0  |   8.0  |   9.0  |  10.0  |  12.0  |\n",
      "RISK  |   0.3% |   0.4% |   0.5% |   0.7% |   0.9% |   1.1% |   1.4% |   1.8% |   2.3% |   2.9% |   3.8% |   4.8% |   6.0% |   7.6% |   9.6% |  12.0% |  14.8% |  22.3% |\n"
     ]
    }
   ],
   "source": [
    "# get Rashomon set and select \n",
    "# Model 2 selected by AH\n",
    "# \n",
    "num_models = min(10, len(multipliers))\n",
    "\n",
    "for model_index in range(num_models):\n",
    "    multiplier = multipliers[model_index]\n",
    "    intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "    coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "\n",
    "    feature_names=list(X_train.columns)\n",
    "    RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients, X_train = X_train)\n",
    "    RiskScoreClassifier_m.reset_featureNames(feature_names)\n",
    "    RiskScoreClassifier_m.print_model_card()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBM loop over test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[numeric_columns] = train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[categorical_columns] = train[categorical_columns].astype('category')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[numeric_columns] = train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[categorical_columns] = train[categorical_columns].astype('category')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[numeric_columns] = train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[categorical_columns] = train[categorical_columns].astype('category')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[numeric_columns] = train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_15072/3930493632.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[categorical_columns] = train[categorical_columns].astype('category')\n"
     ]
    }
   ],
   "source": [
    "auc_ebm=[]\n",
    "\n",
    "for i in range(1, 5):\n",
    "    filename = f\"data_test_{i}_old.csv\"\n",
    "\n",
    "    file = pd.read_csv(filename)\n",
    "    ids=file['ID']\n",
    "\n",
    "    train=all_data[~all_data['ID'].isin(ids)]\n",
    "    test=all_data[all_data['ID'].isin(ids)]\n",
    "\n",
    "    test=test[train.columns]\n",
    "\n",
    "    test.dtypes==train.dtypes\n",
    "\n",
    "    del test[test.columns[0]]\n",
    "    del train[train.columns[0]]\n",
    "\n",
    "\n",
    "    numeric_columns = ['Age', 'Fat','IAT','Sprint_30','SIMS_score','Srpe_7d_robust','Srpe_team_avg','KEB_AB_robust']\n",
    "    train[numeric_columns] = train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    categorical_columns = ['After_RTP', 'Pos_code','SIMS_pain','Matchday','Crit']\n",
    "    train[categorical_columns] = train[categorical_columns].astype('category')\n",
    "\n",
    "    numeric_columns = ['Age', 'Fat','IAT','Sprint_30','SIMS_score','Srpe_7d_robust','Srpe_team_avg','KEB_AB_robust']\n",
    "    test[numeric_columns] = test[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    categorical_columns = ['After_RTP', 'Pos_code','SIMS_pain','Matchday','Crit']\n",
    "    test[categorical_columns] = test[categorical_columns].astype('category')\n",
    "\n",
    "    X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "    X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
    "\n",
    "    ebm=ExplainableBoostingClassifier(\n",
    "            inner_bags=10,\n",
    "            interactions=0,\n",
    "            learning_rate=0.02,\n",
    "            max_bins=20,\n",
    "            max_interaction_bins=16,\n",
    "            max_rounds=20,\n",
    "            outer_bags=12,\n",
    "            validation_size=0.2,\n",
    "            n_jobs=-2,\n",
    "            random_state=12)\n",
    "    \n",
    "    ebm.fit(X_train[['Srpe_team_avg','Srpe_7d_robust','Pos_code','Sprint_30']],y_train)\n",
    "    test_auc=roc_auc_score(y_true=y_test,y_score=ebm.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test,y_score=ebm.predict_proba(X_test)[:,1])    \n",
    "    df = pd.DataFrame(zip(fpr,tpr,thresholds), columns = ['false_positive_rate', 'true_positive_rate', 'thresholds'])   \n",
    "    df.to_csv(\"roc_curve_ebm_\"+str(i)+\".csv\")\n",
    "\n",
    "\n",
    "    auc_ebm.append(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6113775084022712\n",
      "0.05439086384134627\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_ebm))\n",
    "print(np.std(auc_ebm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_82731/1983080263.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[numeric_columns] = train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
      "/var/folders/0_/3hlfdkd50633tgz9cbkx_vcw18f2ds/T/ipykernel_82731/1983080263.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[categorical_columns] = train[categorical_columns].astype('category')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/5041704144/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/5041704144/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = f\"data_test_{1}_old.csv\"\n",
    "\n",
    "file = pd.read_csv(filename)\n",
    "ids=file['ID']\n",
    "\n",
    "train=all_data[~all_data['ID'].isin(ids)]\n",
    "test=all_data[all_data['ID'].isin(ids)]\n",
    "\n",
    "test=test[train.columns]\n",
    "\n",
    "test.dtypes==train.dtypes\n",
    "\n",
    "del test[test.columns[0]]\n",
    "del train[train.columns[0]]\n",
    "\n",
    "\n",
    "numeric_columns = ['Age', 'Fat','IAT','Sprint_30','SIMS_score','Srpe_7d_robust','Srpe_team_avg','KEB_AB_robust']\n",
    "train[numeric_columns] = train[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "categorical_columns = ['After_RTP', 'Pos_code','SIMS_pain','Matchday','Crit']\n",
    "train[categorical_columns] = train[categorical_columns].astype('category')\n",
    "\n",
    "numeric_columns = ['Age', 'Fat','IAT','Sprint_30','SIMS_score','Srpe_7d_robust','Srpe_team_avg','KEB_AB_robust']\n",
    "test[numeric_columns] = test[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "categorical_columns = ['After_RTP', 'Pos_code','SIMS_pain','Matchday','Crit']\n",
    "test[categorical_columns] = test[categorical_columns].astype('category')\n",
    "\n",
    "X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
    "\n",
    "ebm=ExplainableBoostingClassifier(\n",
    "            inner_bags=10,\n",
    "            interactions=0,\n",
    "            learning_rate=0.02,\n",
    "            max_bins=20,\n",
    "            max_interaction_bins=16,\n",
    "            max_rounds=20,\n",
    "            outer_bags=12,\n",
    "            validation_size=0.2,\n",
    "            n_jobs=-2,\n",
    "            random_state=12)\n",
    "ebm.fit(X_train[['Srpe_team_avg','Srpe_7d_robust','Pos_code','Sprint_30']],y_train)\n",
    "\n",
    "\n",
    "show(ebm.explain_global())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature       Type    Value     Score     upper     lower Category\n",
      "0   Srpe_team_avg  Numerical    0.000 -0.004466 -0.003770 -0.005161      NaN\n",
      "1   Srpe_team_avg  Numerical    1.000 -0.004137 -0.003462 -0.004812      NaN\n",
      "2   Srpe_team_avg  Numerical   48.500 -0.003506 -0.002779 -0.004234      NaN\n",
      "3   Srpe_team_avg  Numerical  103.500 -0.002951 -0.002224 -0.003679      NaN\n",
      "4   Srpe_team_avg  Numerical  181.000 -0.002351 -0.001644 -0.003059      NaN\n",
      "..            ...        ...      ...       ...       ...       ...      ...\n",
      "56      Sprint_30  Numerical    4.185  0.000870  0.001581  0.000160      NaN\n",
      "57      Sprint_30  Numerical    4.205  0.000852  0.001493  0.000211      NaN\n",
      "58      Sprint_30  Numerical    4.245  0.001643  0.002363  0.000924      NaN\n",
      "59      Sprint_30  Numerical    4.325  0.001823  0.002665  0.000981      NaN\n",
      "60      Sprint_30  Numerical    5.620  0.001823  0.002665  0.000981      NaN\n",
      "\n",
      "[61 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# extract data to plot using ggplot instead of visualization provided by ebm.explain_global()\n",
    "\n",
    "ebm_global=ebm.explain_global()\n",
    "feature_data = []\n",
    "#Loop through all features (numerical and categorical)\n",
    "for i in range(len(ebm_global.data()['names'])):\n",
    "    data_names = ebm_global.data()\n",
    "    feature_name = data_names['names'][i]\n",
    "    shape_data = ebm_global.data(i)\n",
    "\n",
    "    # Check if the feature is not an interaction\n",
    "    if shape_data['type'] == 'univariate':\n",
    "        \n",
    "        # Detect categorical features if names or values are strings\n",
    "        if isinstance(shape_data['names'][0], str):\n",
    "            # Extract categories and corresponding scores\n",
    "            categories = shape_data['names']\n",
    "            scores = shape_data['scores']\n",
    "            upper_bounds = shape_data['upper_bounds']\n",
    "            lower_bounds = shape_data['lower_bounds']\n",
    "            \n",
    "            # Loop through and store the category data\n",
    "            for category, score, upper_bounds, lower_bounds in zip(categories, scores,upper_bounds, lower_bounds):\n",
    "                feature_data.append({\n",
    "                    'Feature': feature_name,\n",
    "                    'Type': 'Categorical',\n",
    "                    'Category': category,\n",
    "                    'Score': score,\n",
    "                    'upper':upper_bounds,\n",
    "                    'lower':lower_bounds\n",
    "                })\n",
    "        \n",
    "        # Detect numerical features if names or values are floats or integers\n",
    "        elif isinstance(shape_data['names'][0], (int, float)):\n",
    "            # Extract bin edges and corresponding scores\n",
    "            x_values = shape_data['names']\n",
    "            scores = shape_data['scores']\n",
    "            upper_bounds = shape_data['upper_bounds']\n",
    "            lower_bounds = shape_data['lower_bounds']\n",
    "            \n",
    "            # Loop through and store the bin data\n",
    "            for x_values, score, upper_bounds, lower_bounds in zip(x_values, scores,upper_bounds,lower_bounds):\n",
    "                feature_data.append({\n",
    "                    'Feature': feature_name,\n",
    "                    'Type': 'Numerical',\n",
    "                    'Value': x_values,\n",
    "                    'Score': score,\n",
    "                    'upper':upper_bounds,\n",
    "                    'lower':lower_bounds\n",
    "                })\n",
    "\n",
    "            score_range = shape_data['names']\n",
    "            max_range_value = max(score_range)\n",
    "            second_last_score = scores[-1]  # Last score or second-to-last value\n",
    "            \n",
    "            # Add the new max range bin\n",
    "            feature_data.append({\n",
    "                'Feature': feature_name,\n",
    "                'Type': 'Numerical',\n",
    "                'Value': max_range_value,\n",
    "                'Score': second_last_score,  # Use the second-to-last score\n",
    "                'upper': upper_bounds,  # Keep the same upper bound as the last bin\n",
    "                'lower': lower_bounds   # Keep the same lower bound as the last bin\n",
    "            })\n",
    "\n",
    "# Convert the list of dictionaries into a pandas DataFrame\n",
    "feature_df = pd.DataFrame(feature_data)\n",
    "feature_df.to_csv(\"feature_data.csv\", index=False)\n",
    "print(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note at this point: switch to R code to see ggplot visualization. The script is called plots.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use synthetic data to show that the code works\n",
    "\n",
    "Here, we will be using synthetic data generated using the original data used in Hecksteden et al. (2022). This is purely to show that the code works, in addition to the code above used to generate orginal results presented in the commentary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "from sdv.metadata import Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv(\"/Users/berger/Documents/soccer/positron_project/data_ml_praevent.csv\")\n",
    "len(np.unique(all_data['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate 100 rows for every player in original data\n",
    "\n",
    "synth=pd.DataFrame()\n",
    "for iter, player in enumerate(np.unique(all_data['ID'])):\n",
    "    \n",
    "    #player=105\n",
    "    temp=all_data[all_data['ID']==player]\n",
    "\n",
    "    #y=temp['Crit']\n",
    "    temp=temp.drop(columns=['ID'])\n",
    "\n",
    "    synthesizer = GaussianCopulaSynthesizer(Metadata.detect_from_dataframe(temp), enforce_min_max_values=False, enforce_rounding=False)\n",
    "    synthesizer.fit(data=temp)\n",
    "\n",
    "    synthetic_data = synthesizer.sample(num_rows=100)\n",
    "    synthetic_data\n",
    "\n",
    "    synth=synth.append(synthetic_data)\n",
    "\n",
    "synth.to_csv(\"synthetic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fasterrisk on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth=pd.read_csv(\"synthetic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>After_RTP</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pos_code</th>\n",
       "      <th>VV_resid_age</th>\n",
       "      <th>Fat</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Sprint_30</th>\n",
       "      <th>SIMS_score</th>\n",
       "      <th>SIMS_pain</th>\n",
       "      <th>Srpe_7d_robust</th>\n",
       "      <th>Matchday</th>\n",
       "      <th>Srpe_team_avg</th>\n",
       "      <th>KEB_AB_robust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>149.335755</td>\n",
       "      <td>12.55972</td>\n",
       "      <td>12.996188</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>13.485</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.846467</td>\n",
       "      <td>nein</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>175.930113</td>\n",
       "      <td>14.40000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>4.336528</td>\n",
       "      <td>13.875</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.830450</td>\n",
       "      <td>nein</td>\n",
       "      <td>359</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>175.930113</td>\n",
       "      <td>14.40000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>4.336528</td>\n",
       "      <td>13.875</td>\n",
       "      <td>0</td>\n",
       "      <td>1.259789</td>\n",
       "      <td>ja</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>175.930113</td>\n",
       "      <td>14.40000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>4.336528</td>\n",
       "      <td>13.875</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.352950</td>\n",
       "      <td>nein</td>\n",
       "      <td>59</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>175.930113</td>\n",
       "      <td>14.40000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>4.336528</td>\n",
       "      <td>13.875</td>\n",
       "      <td>0</td>\n",
       "      <td>1.115926</td>\n",
       "      <td>nein</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.530232</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>19.875</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.748555</td>\n",
       "      <td>ja</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8796</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-30.965315</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>19.875</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.416780</td>\n",
       "      <td>nein</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8797</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.046713</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>19.875</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.707965</td>\n",
       "      <td>nein</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.991478</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>19.875</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023238</td>\n",
       "      <td>nein</td>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.646007</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>19.875</td>\n",
       "      <td>0</td>\n",
       "      <td>1.638872</td>\n",
       "      <td>nein</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      After_RTP  Age  Pos_code  VV_resid_age       Fat        IAT  Sprint_30  \\\n",
       "0             0   29         0    149.335755  12.55972  12.996188   4.210000   \n",
       "1             0   28         0    175.930113  14.40000  13.200000   4.336528   \n",
       "2             0   28         0    175.930113  14.40000  13.200000   4.336528   \n",
       "3             0   28         0    175.930113  14.40000  13.200000   4.336528   \n",
       "4             0   28         0    175.930113  14.40000  13.200000   4.336528   \n",
       "...         ...  ...       ...           ...       ...        ...        ...   \n",
       "8795          1   19         0    -20.530232  15.00000  14.800000   4.030000   \n",
       "8796          0   19         0    -30.965315  15.00000  14.800000   4.030000   \n",
       "8797          1   19         0    -18.046713  15.00000  14.800000   4.030000   \n",
       "8798          0   19         0     -9.991478  15.00000  14.800000   4.030000   \n",
       "8799          0   19         0     -5.646007  15.00000  14.800000   4.030000   \n",
       "\n",
       "      SIMS_score  SIMS_pain  Srpe_7d_robust Matchday  Srpe_team_avg  \\\n",
       "0         13.485          0       -0.846467     nein            243   \n",
       "1         13.875          0       -0.830450     nein            359   \n",
       "2         13.875          0        1.259789       ja            481   \n",
       "3         13.875          0       -1.352950     nein             59   \n",
       "4         13.875          0        1.115926     nein            380   \n",
       "...          ...        ...             ...      ...            ...   \n",
       "8795      19.875          0       -0.748555       ja            475   \n",
       "8796      19.875          0       -1.416780     nein            363   \n",
       "8797      19.875          0       -0.707965     nein             97   \n",
       "8798      19.875          0       -0.023238     nein            470   \n",
       "8799      19.875          0        1.638872     nein            626   \n",
       "\n",
       "      KEB_AB_robust  \n",
       "0                 0  \n",
       "1                -1  \n",
       "2                 0  \n",
       "3                -1  \n",
       "4                 0  \n",
       "...             ...  \n",
       "8795              0  \n",
       "8796              0  \n",
       "8797              0  \n",
       "8798              1  \n",
       "8799              0  \n",
       "\n",
       "[8800 rows x 13 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=synth['Crit']\n",
    "X=synth.drop(columns=[\"Crit\",\"Unnamed: 0\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting continuous features to binary features in the dataframe......\n",
      "We select thresholds for each continuous feature by sampling (without replacement) <= max_num_thresholds_per_feature values from all unique values in that feature column.\n",
      "Finish converting continuous features to binary features......\n"
     ]
    }
   ],
   "source": [
    "binarized, featureIndex_to_groupIndex=convert_continuous_df_to_binary_df(X,max_num_thresholds_per_feature=25,get_featureIndex_to_groupIndex=True)\n",
    "binarized\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(binarized,y,test_size=.2,random_state=42)\n",
    "\n",
    "y_train_frisk=np.asarray(y_train)\n",
    "y_train_frisk[y_train_frisk == 1] = 1\n",
    "y_train_frisk[y_train_frisk == 0] = -1\n",
    "y_train_frisk\n",
    "y_test_frisk=np.asarray(y_test)\n",
    "y_test_frisk[y_test_frisk == 1] = 1\n",
    "y_test_frisk[y_test_frisk == 0] = -1\n",
    "y_test_frisk\n",
    "\n",
    "\n",
    "sparsity = 8\n",
    "parent_size = 10\n",
    "ub=10\n",
    "lb=ub*-1\n",
    "sparsity_constraint=8\n",
    "\n",
    "RiskScoreOptimizer_m = RiskScoreOptimizer(X = np.array(X_train), y = y_train_frisk, \n",
    "    k = sparsity,\n",
    "    parent_size=parent_size, \n",
    "    select_top_m=1,\n",
    "    ub=ub,\n",
    "    lb=lb,\n",
    "    maxAttempts=10,\n",
    "    featureIndex_to_groupIndex = featureIndex_to_groupIndex,\n",
    "    group_sparsity=sparsity_constraint)\n",
    "\n",
    "\n",
    "\n",
    "RiskScoreOptimizer_m.optimize()\n",
    "multipliers, sparseDiversePool_beta0_integer, sparseDiversePool_betas_integer = RiskScoreOptimizer_m.get_models()\n",
    "model_index = 0 # first model\n",
    "multiplier = multipliers[model_index]\n",
    "intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "#RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients)\n",
    "\n",
    "feature_names=list(X_train.columns)\n",
    "RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients, X_train = X_train)\n",
    "#RiskScoreClassifier_m.reset_featureNames(feature_names)\n",
    "#RiskScoreClassifier_m.print_model_card()\n",
    "\n",
    "y_test_pred=RiskScoreClassifier_m.predict_prob(np.asarray(X_test))\n",
    "\n",
    "test_acc, test_auc = RiskScoreClassifier_m.get_acc_and_auc(np.asarray(X_test), y_test_frisk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909026195899773\n"
     ]
    }
   ],
   "source": [
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Risk Score is:\n",
      "1.              Fat<=9.005563726609063     -4 point(s) |   ...\n",
      "2.               Fat<=9.33690095015295      7 point(s) | + ...\n",
      "3.             IAT<=13.644931546399306     -2 point(s) | + ...\n",
      "4.        Sprint_30<=4.019416735365593     -2 point(s) | + ...\n",
      "5.                    SIMS_score<=21.5      5 point(s) | + ...\n",
      "6. Srpe_7d_robust<=-0.8503627156519471      3 point(s) | + ...\n",
      "7.  Srpe_7d_robust<=0.3092389238165474      2 point(s) | + ...\n",
      "8.                  Srpe_team_avg<=131     -2 point(s) | + ...\n",
      "                                                 SCORE | =    \n",
      "SCORE |  -10.0  |  -8.0  |  -7.0  |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |   2.0  |   3.0  |\n",
      "RISK  |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |   0.0% |\n",
      "SCORE |   4.0  |   5.0  |   6.0  |   7.0  |   8.0  |   9.0  |  10.0  |  11.0  |  12.0  |  13.0  |  14.0  |  15.0  |  17.0  |\n",
      "RISK  |   0.0% |   0.1% |   0.1% |   0.2% |   0.3% |   0.5% |   0.8% |   1.3% |   2.1% |   3.4% |   5.4% |   8.4% |  19.2% |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names=list(binarized.columns)\n",
    "RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients, X_train = X_train)\n",
    "RiskScoreClassifier_m.reset_featureNames(feature_names)\n",
    "RiskScoreClassifier_m.print_model_card()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EBM on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_columns = ['Age', 'Fat','IAT','Sprint_30','SIMS_score','Srpe_7d_robust','Srpe_team_avg','KEB_AB_robust']\n",
    "X[numeric_columns] = X[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "categorical_columns = ['After_RTP', 'Pos_code','SIMS_pain','Matchday']\n",
    "X[categorical_columns] = X[categorical_columns].astype('category')\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=.2,random_state=42)\n",
    "\n",
    "\n",
    "ebm=ExplainableBoostingClassifier(\n",
    "        inner_bags=10,\n",
    "        interactions=0,\n",
    "        learning_rate=0.02,\n",
    "        max_bins=20,\n",
    "        max_interaction_bins=16,\n",
    "        max_rounds=20,\n",
    "        outer_bags=12,\n",
    "        validation_size=0.2,\n",
    "        n_jobs=-2,\n",
    "        random_state=12)\n",
    "\n",
    "ebm.fit(X_train[['Srpe_team_avg','Srpe_7d_robust','Pos_code','Sprint_30']],y_train)\n",
    "test_auc=roc_auc_score(y_true=y_test,y_score=ebm.predict_proba(X_test)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5410734624145785\n"
     ]
    }
   ],
   "source": [
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/14492857776/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/14492857776/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "show(ebm.explain_global())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
